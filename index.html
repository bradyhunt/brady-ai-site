<!DOCTYPE html>
<html lang="en">

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Brady Hunt


</title>
<meta name="description" content="Personal website of Brady Hunt
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Favicon -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22></text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="https://brady.ai/">



  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
        <!-- Social Icons -->
        <div class="navbar-brand social">
          <a href="mailto:%62%72%61%64%79.%68%75%6E%74@%64%61%72%74%6D%6F%75%74%68.%65%64%75" title="email"><i class="fas fa-envelope"></i></a>
<a href="https://www.linkedin.com/in/bradyhunt" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a>
<a href="https://scholar.google.com/citations?user=Z-kmpr4AAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a>
<a href="https://github.com/bradyhunt" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a>
<a href="https://orcid.org/0000-0002-1143-7668" title="ORCID" target="_blank" rel="noopener noreferrer"><i class="ai ai-orcid"></i></a>

<a href="https://publons.com/a/AAW-1580-2020/" title="Publons" target="_blank" rel="noopener noreferrer"><i class="ai ai-publons"></i></a>

        </div>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              About
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                Publications
                
              </a>
          </li>
          
          
          
          
          
          
          
          <!-- CV -->
          <li class="nav-item">
            <a class="nav-link" href="https://drive.google.com/file/d/1XtU-0HS5xdLxPujOuDB2BYCkJkdwQ5xe/view?usp=sharing" target="_blank" rel="noopener noreferrer">CV</a>
          </li>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     Brady Hunt
    </h1>
     <p class="desc"></p>
  </header>

  <article>
    
    <div class="profile float-left">
      
        <picture>
    
    <source media="(max-width: 480px)" srcset="/assets/resized/prof_pic-480x556.jpg">
    
    <source media="(max-width: 800px)" srcset="/assets/resized/prof_pic-800x927.jpg">
    
    <img class="img-fluid z-depth-1 rounded" src="/assets/img/prof_pic.jpg" alt="prof_pic.jpg">
</source></source></picture>

      
      
    </div>
    

    <div class="clearfix">
      <p>I am a Research Scientist in the <a href="https://sites.dartmouth.edu/optmed/about-us/laboratory-faculty/" target="_blank" rel="noopener noreferrer">Optics in Medicine</a> lab at Dartmouth, where I work on <a href="https://onlinelibrary.wiley.com/doi/10.1002/lsm.23414" target="_blank" rel="noopener noreferrer">AI-powered imaging systems</a> for real-time treatment guidance in radiotherapy, surgery, and dermatology applications. I believe that <a href="https://hazyresearch.stanford.edu/data-centric-ai" target="_blank" rel="noopener noreferrer">Data-centric AI</a> is the most promising pathway to achieve AI adoption in medicine. I seek to deeply understand how data (particularly image/video) informs decision making in both high- and low-resource healthcare settings and where AI-powered tools can be most transformative. I bridge multiple domains of engineering to bring sensors, data, ML and clincians together in conducting my research at the <a href="https://www.dartmouth-hitchcock.org/" target="_blank" rel="noopener noreferrer">Dartmouth-Hitchcock Medical Center</a>.</p>

<p>Prior to joining Dartmouth, I completed my PhD in Bioengineering under the mentorship of <a href="https://kortum.rice.edu/people/rebecca-richards-kortum" target="_blank" rel="noopener noreferrer">Rebecca Richards-Kortum</a> at Rice University. At Rice, I led efforts to transform cervical cancer prevention using point-of-care imaging technologies in medically underserved populations. I was fortunate to spend time working in three different cancer centers in <a href="https://onlinelibrary.wiley.com/doi/10.1002/ijc.33543" target="_blank" rel="noopener noreferrer">Brazil</a>, <a href="https://www.basichealth.org/our-work/where-we-work/el-salvador/" target="_blank" rel="noopener noreferrer">El Salvador</a>, and <a href="https://www.nationalacademies.org/our-work/peerccspt/evaluating-innovative-technologies-and-approaches-to-addressing-cervical-cancer-in-the-republic-of-mozambique" target="_blank" rel="noopener noreferrer">Mozambique</a>. Prior to my work at Rice, I obtained my Bachelor’s degree in Biophysics <i>magna cum laude</i> from Brigham Young University.</p>

    </div>

    
      <div class="news">
  <h2>Latest News</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Jan 2022</th>
          <td>
            
              Accepted a position as a machine learning scientist and junior faculty in <a href="https://cancer.dartmouth.edu/radiation-oncology/radiation-oncology-team" target="_blank" rel="noopener noreferrer">Radiation Oncology</a> at Dartmouth-Hitchcock! (<a href="https://www.dropbox.com/s/4lmb2w8bby255d8/brady_hunt_faculty_slide.pptx?dl=0" target="_blank" rel="noopener noreferrer">Faculty Slide</a>)

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Nov 2021</th>
          <td>
            
              My research on a low-cost, compact smartphone attachment for fluorescence measurements of the skin was published in Biomedical Optics Express! Find it <a href="https://dx.doi.org/10.1364%2FBOE.439342" target="_blank" rel="noopener noreferrer">here</a>.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Sep 2021</th>
          <td>
            
              Presented my work on deep-learning based cine MRI image registration for target tracking during radiotherapy at CMIMI 2021. (<a href="https://cdn.ymaws.com/siim.org/resource/resmgr/mimi21/sessions/c2004/deep_learning-based_deformab.pdf" target="_blank" rel="noopener noreferrer">Abstract</a>/<a href="https://www.dropbox.com/s/teb5yrjp549cuiu/BRADY_HUNT_CMIMI21.pdf?dl=0" target="_blank" rel="noopener noreferrer">Slides</a>)

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Apr 2021</th>
          <td>
            
              Co-authored a review article with colleagues in the biomedical optics community summarizing the state of <a href="https://doi.org/10.1002/lsm.23414" target="_blank" rel="noopener noreferrer">Deep Learning in Biomedical Optics</a>.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Apr 2021</th>
          <td>
            
              My review article on Smartphone-based Imaging in Medicine with Brian Pogue and Alberto Ruiz was featured by SPIE! (<a href="https://www.eurekalert.org/news-releases/542234" target="_blank" rel="noopener noreferrer">Press</a>/<a href="https://doi.org/10.1117/1.JBO.26.4.040902" target="_blank" rel="noopener noreferrer">Publication</a>)

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Feb 2021</th>
          <td>
            
              My work on deep-learning based gantry motion artifact reduction was accepted to the Young Investigator’s session at the AAPM Spring Clinical meeting! (<a href="https://sites.dartmouth.edu/medphys/2021/02/12/three-dartmouth-researchers-accepted-for-early-career-symposium/" target="_blank" rel="noopener noreferrer">Announcement</a>/<a href="https://www.dropbox.com/s/u42k1duksig8grj/BH_GANTRY_GAN_2021SCM.mp4?dl=0" target="_blank" rel="noopener noreferrer">Video</a>)

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Feb 2021</th>
          <td>
            
              Our <a href="https://doi.org/10.1002/ijc.33543" target="_blank" rel="noopener noreferrer">1,600 patient prospective trial</a> on automated diagnosis using high-resolution microendoscopy using computer vision was accepted for publication at IJC.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Oct 2020</th>
          <td>
            
              Attended MICCAI 2020 virtually and took 3rd place in the <a href="https://monai.medium.com/first-ever-monai-bootcamp-recap-8edc462e57cc" target="_blank" rel="noopener noreferrer">MONAI bootcamp</a> COVID-19 X-ray challenge.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Sep 2020</th>
          <td>
            
              Joined the Thayer School of Engineering at Dartmouth as a research scientist in the <a href="https://sites.dartmouth.edu/optmed/about-us/laboratory-faculty/" target="_blank" rel="noopener noreferrer">Optics in Medicine</a> group!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">May 2020</th>
          <td>
            
              Defended my PhD thesis at Rice! (<a href="https://www.dropbox.com/s/xz8ax5srjs7eefi/hunt-defense-presentation.pdf?dl=0" target="_blank" rel="noopener noreferrer">Slides</a>/<a href="https://scholarship.rice.edu/handle/1911/109104" target="_blank" rel="noopener noreferrer">PDF</a>)

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    

    
      <div class="publications">
  <h2>Research highlights</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-3">
    
      <img class="img-fluid" src="/assets/pubimg/hunt2021ultracompact.gif">
    
  </div>

  <div id="hunt2021ultracompact" class="col-sm-8">
    
      <div class="title">Ultracompact fluorescence smartphone attachment using built-in optics for protoporphyrin-IX quantification in skin</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hunt, Brady</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Streeter, Samuel S,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ruiz, Alberto J,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Chapman, M Shane,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Pogue, Brian W
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Biomedical Optics Express</em>
      
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://www.osapublishing.org/boe/fulltext.cfm?uri=boe-12-11-6995&amp;id=460701" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
    
    
    
      <a href="https://github.com/optmed/CompactFluorescenceCam" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
    
    
      
      <a href="https://www.dropbox.com/s/g2kb9gxq4hjiv5n/PW21_BiOS_cfcam_poster_28.5x40.pdf?dl=0" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Poster</a>
      
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Smartphone-based fluorescence imaging systems have the potential to provide convenient quantitative image guidance at the point of care. However, common approaches have required the addition of complex optical attachments, which reduce translation potential. In this study, a simple clip-on attachment appropriate for fluorescence imaging of protoporphyrin-IX (PpIX) in skin was designed using the built-in light source and ultrawide camera sensor of a smartphone. Software control for image acquisition and quantitative analysis was developed using the 10-bit video capability of the phone. Optical performance was characterized using PpIX in liquid tissue phantoms and endogenously produced PpIX in mice and human skin. The proposed system achieves a very compact form factor (&lt;30 cm3) and can be readily fabricated using widely available low-cost materials. The limit of detection of PpIX in optical phantoms was &lt;10 nM, with good signal linearity from 10 to 1000 nM (R2 &gt;0.99). Both murine and human skin imaging verified that in vivo PpIX fluorescence was detected within 1 hour of applying aminolevulinic acid (ALA) gel. This ultracompact handheld system for quantification of PpIX in skin is well-suited for dermatology clinical workflows.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-3">
    
      <img class="img-fluid" src="/assets/pubimg/streeter2021developing.jpg">
    
  </div>

  <div id="streeter2021developing" class="col-sm-8">
    
      <div class="title">Developing diagnostic assessment of breast lumpectomy tissues using radiomic and optical signatures</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Streeter, Samuel S,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Hunt, Brady</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Zuurbier, Rebecca A,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Wells, Wendy A,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Paulsen, Keith D,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Pogue, Brian W
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Scientific reports</em>
      
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://www.nature.com/articles/s41598-021-01414-z" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
    
    
    
      <a href="https://github.com/optmed/radiomics-optomics" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>High positive margin rates in oncologic breast-conserving surgery are a pressing clinical problem. Volumetric X-ray scanning is emerging as a powerful ex vivo specimen imaging technique for analyzing resection margins, but X-rays lack contrast between non-malignant and malignant fibrous tissues. In this study, combined micro-CT and wide-field optical image radiomics were developed to classify malignancy of breast cancer tissues, demonstrating that X-ray/optical radiomics improve malignancy classification. Ninety-two standardized features were extracted from co-registered micro-CT and optical spatial frequency domain imaging samples extracted from 54 breast tumors exhibiting seven tissue subtypes confirmed by microscopic histological analysis. Multimodal feature sets improved classification performance versus micro-CT alone when adipose samples were included (AUC = 0.88 vs. 0.90; p-value = 3.65e−11) and excluded, focusing the classification task on exclusively non-malignant fibrous versus malignant tissues (AUC = 0.78 vs. 0.85; p-value = 9.33e−14). Extending the radiomics approach to high-dimensional optical data—termed “optomics” in this study—offers a promising optical image analysis technique for cancer detection.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-3">
    
      <img class="img-fluid" src="/assets/pubimg/tian2021deep.jpg">
    
  </div>

  <div id="tian2021deep" class="col-sm-8">
    
      <div class="title">Deep learning in biomedical optics</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Tian, Lei,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Hunt, Brady</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Bell, Muyinatu A Lediju,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yi, Ji,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Smith, Jason T,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ochoa, Marien,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Intes, Xavier,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Durr, Nicholas J
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Lasers in Surgery and Medicine</em>
      
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1002/lsm.23414" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This article reviews deep learning applications in biomedical optics with a particular emphasis on image formation. The review is organized by imaging domains within biomedical optics and includes microscopy, fluorescence lifetime imaging, in vivo microscopy, widefield endoscopy, optical coherence tomography, photoacoustic imaging, diffuse tomography, and functional optical brain imaging. For each of these domains, we summarize how deep learning has been applied and highlight methods by which deep learning can enable new capabilities for optics in medicine. Challenges and opportunities to improve translation and adoption of deep learning in biomedical optics are also summarized.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-3">
    
      <img class="img-fluid" src="/assets/pubimg/hunt2021high.gif">
    
  </div>

  <div id="hunt2021high" class="col-sm-8">
    
      <div class="title">High frame rate video mosaicking microendoscope to image large regions of intact tissue with subcellular resolution</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hunt, Brady</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Coole, Jackson,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Brenes, David,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kortum, Alex,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Mitbander, Ruchika,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Vohra, Imran,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Carns, Jennifer,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Schwarz, Richard,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Richards-Kortum, Rebecca
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Biomedical Optics Express</em>
      
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1364/BOE.425527" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
    
    
    
      <a href="https://github.com/bradyhunt/VMM" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>High-resolution microendoscopy (HRME) is a low-cost strategy to acquire images of intact tissue with subcellular resolution at frame rates ranging from 11 to 18 fps. Current HRME imaging strategies are limited by the small microendoscope field of view (∼0.5 mm2); multiple images must be acquired and reliably registered to assess large regions of clinical interest. Image mosaics have been assembled from co-registered frames of video acquired as a microendoscope is slowly moved across the tissue surface, but the slow frame rate of previous HRME systems made this approach impractical for acquiring quality mosaicked images from large regions of interest. Here, we present a novel video mosaicking microendoscope incorporating a high frame rate CMOS sensor and optical probe holder to enable high-speed, high quality interrogation of large tissue regions of interest. Microendoscopy videos acquired at &gt;90 fps are assembled into an image mosaic. We assessed registration accuracy and image sharpness across the mosaic for images acquired with a handheld probe over a range of translational speeds. This high frame rate video mosaicking microendoscope enables in vivo probe translation at &gt;15 millimeters per second while preserving high image quality and accurate mosaicking, increasing the size of the region of interest that can be interrogated at high resolution from 0.5 mm2 to &gt;30 mm2. Real-time deployment of this high-frame rate system is demonstrated in vivo and source code made publicly available.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-3">
    
      <img class="img-fluid" src="/assets/pubimg/hunt2021cervical.png">
    
  </div>

  <div id="hunt2021cervical" class="col-sm-8">
    
      <div class="title">Cervical lesion assessment using real-time microendoscopy image analysis in Brazil: The CLARA study</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Hunt, Brady</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Fregnani, José Humberto Tavares Guerreiro,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Brenes, David,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Schwarz, Richard A,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Salcedo, Mila P,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Possati-Resende, Júlio César,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Antoniazzi, Márcio,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Oliveira Fonseca, Bruno,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Santana, Iara Viana Vidigal,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Macêdo Matsushita, Graziela,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and others, 
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>International journal of cancer</em>
      
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/ijc.33543" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We conducted a prospective evaluation of the diagnostic performance of high-resolution microendoscopy (HRME) to detect cervical intraepithelial neoplasia (CIN) in women with abnormal screening tests. Study participants underwent colposcopy, HRME and cervical biopsy. The prospective diagnostic performance of HRME using an automated morphologic image analysis algorithm was compared to that of colposcopy using histopathologic detection of CIN as the gold standard. To assess the potential to further improve performance of HRME image analysis, we also conducted a retrospective analysis assessing performance of a multi-task convolutional neural network to segment and classify HRME images. One thousand four hundred eighty-six subjects completed the study; 435 (29%) subjects had CIN Grade 2 or more severe (CIN2+) diagnosis. HRME with morphologic image analysis for detection of CIN Grade 3 or more severe diagnoses (CIN3+) was similarly sensitive (95.6% vs 96.2%, P = .81) and specific (56.6% vs 58.7%, P = .18) as colposcopy. HRME with morphologic image analysis for detection of CIN2+ was slightly less sensitive (91.7% vs 95.6%, P 
    </p>
</div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
</ol>
</div>

    

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container">
    © Copyright 2022 Brady  Hunt.
    Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme.

    
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

  
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  





</html>
